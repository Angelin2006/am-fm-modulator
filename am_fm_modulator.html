<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>AM / FM Modulator — Audio In → Message / Carrier / Modulated</title>
  <style>
    body { font-family: Inter, system-ui, -apple-system, Arial; margin: 18px; background:#f7f9fc; color:#111 }
    h1 { font-size:20px }
    .controls { display:flex; gap:12px; flex-wrap:wrap; margin-bottom:12px }
    label { display:flex; flex-direction:column; font-size:13px }
    input[type="range"] { width:200px }
    canvas { background:#fff; border:1px solid #ddd; border-radius:6px; }
    .row { display:flex; gap:12px; margin-top:12px; align-items:flex-start }
    .col { flex:1 }
    button { padding:8px 12px; border-radius:6px; border:1px solid #bbb; background:#fff; cursor:pointer }
    button.primary { background:#2563eb; color:#fff; border-color:#1e40af }
    small { color:#555 }
  </style>
</head>
<body>
  <h1>AM / FM Modulator — feed an audio file (or speak) and generate AM/FM</h1>
  <div class="controls">
    <label>Choose audio file (wav/mp3)
      <input type="file" id="audioFile" accept="audio/*">
    </label>
    <label>Carrier freq (Hz)
      <input id="carrierFreq" type="number" value="10000" min="100" step="10">
    </label>
    <label>AM modulation index (0 - 1)
      <input id="amIndex" type="range" min="0" max="1" step="0.01" value="0.6">
      <small id="amIndexVal">0.60</small>
    </label>
    <label>FM freq deviation (Hz)
      <input id="fmDev" type="number" value="3000" min="0" step="10">
    </label>
    <label>Preview sample rate
      <input id="sampleRate" type="number" value="44100" min="8000" max="96000" step="1000">
    </label>
  </div>

  <div class="controls">
    <button id="loadMic">Use Microphone</button>
    <button id="processBtn" class="primary">Process & Generate AM/FM</button>
    <button id="downloadAM">Download AM (WAV)</button>
    <button id="downloadFM">Download FM (WAV)</button>
    <button id="playMsg">Play Message</button>
    <button id="playAM">Play AM</button>
    <button id="playFM">Play FM</button>
  </div>

  <div class="row">
    <div class="col">
      <h3>Message (input) waveform</h3>
      <canvas id="msgCanvas" width="800" height="150"></canvas>
    </div>
    <div class="col">
      <h3>Carrier waveform (preview)</h3>
      <canvas id="carrierCanvas" width="800" height="150"></canvas>
    </div>
  </div>

  <div class="row">
    <div class="col">
      <h3>AM waveform (preview)</h3>
      <canvas id="amCanvas" width="800" height="150"></canvas>
    </div>
    <div class="col">
      <h3>FM waveform (preview)</h3>
      <canvas id="fmCanvas" width="800" height="150"></canvas>
    </div>
  </div>

<script>
// Utility: read file into AudioBuffer
const audioFileEl = document.getElementById('audioFile');
const carrierFreqEl = document.getElementById('carrierFreq');
const amIndexEl = document.getElementById('amIndex');
const amIndexVal = document.getElementById('amIndexVal');
const fmDevEl = document.getElementById('fmDev');
const sampleRateEl = document.getElementById('sampleRate');
const processBtn = document.getElementById('processBtn');
const downloadAM = document.getElementById('downloadAM');
const downloadFM = document.getElementById('downloadFM');
const playMsg = document.getElementById('playMsg');
const playAM = document.getElementById('playAM');
const playFM = document.getElementById('playFM');
const loadMic = document.getElementById('loadMic');

let audioCtx = new (window.AudioContext || window.webkitAudioContext)();
let rawMessage = null; // Float32Array normalized -1..1
let sr = 44100;
let amBuffer = null, fmBuffer = null, messageBuffer = null;

amIndexEl.addEventListener('input', ()=> amIndexVal.textContent = parseFloat(amIndexEl.value).toFixed(2));

// Canvas drawing helpers
function drawWave(canvas, samples, downsample=1){
  const ctx = canvas.getContext('2d');
  ctx.clearRect(0,0,canvas.width,canvas.height);
  ctx.beginPath();
  ctx.fillStyle = '#fff';
  ctx.fillRect(0,0,canvas.width,canvas.height);
  ctx.strokeStyle = '#111';
  ctx.lineWidth = 1;
  const h = canvas.height, w = canvas.width;
  const mid = h/2;
  ctx.moveTo(0,mid);
  const len = Math.floor(samples.length / downsample);
  for(let i=0;i<len;i++){
    const v = samples[i*downsample];
    const x = (i/len)*w;
    const y = mid - v*mid*0.9;
    ctx.lineTo(x,y);
  }
  ctx.stroke();
}

async function decodeFileToMonoFloat(file){
  const arrayBuffer = await file.arrayBuffer();
  const decoded = await audioCtx.decodeAudioData(arrayBuffer);
  // mix down to mono
  const ch = decoded.numberOfChannels;
  const data = decoded.getChannelData(0);
  if(ch>1){
    const d1 = decoded.getChannelData(1);
    for(let i=0;i<data.length;i++) data[i] = 0.5*(data[i]+d1[i]);
  }
  return {samples: data, sampleRate: decoded.sampleRate};
}

async function useMicrophone(){
  const stream = await navigator.mediaDevices.getUserMedia({audio:true});
  const micSrc = audioCtx.createMediaStreamSource(stream);
  // record a short clip using ScriptProcessor or MediaRecorder
  // we'll use MediaRecorder for simplicity (wav/webm)
  const recorder = new MediaRecorder(stream);
  const chunks = [];
  recorder.ondataavailable = e => chunks.push(e.data);
  recorder.onstop = async ()=>{
    const blob = new Blob(chunks);
    const file = new File([blob],'mic.wav',{type:blob.type});
    const decoded = await decodeFileToMonoFloat(file);
    processRawMessage(decoded.samples, decoded.sampleRate);
  };
  recorder.start();
  loadMic.textContent = 'Recording... Click to stop';
  loadMic.onclick = ()=>{ recorder.stop(); loadMic.textContent='Use Microphone'; loadMic.onclick = useMicrophone; };
}
loadMic.onclick = useMicrophone;

audioFileEl.addEventListener('change', async (e)=>{
  const f = e.target.files[0];
  if(!f) return;
  const decoded = await decodeFileToMonoFloat(f);
  processRawMessage(decoded.samples, decoded.sampleRate);
});

function processRawMessage(samples, fileSR){
  // convert to desired sampleRate (resample if needed)
  sr = parseInt(sampleRateEl.value) || 44100;
  const ratio = fileSR / sr;
  let out;
  if(ratio === 1){
    out = new Float32Array(samples);
  } else {
    // simple nearest/neighbour resample
    const newLen = Math.floor(samples.length / ratio);
    out = new Float32Array(newLen);
    for(let i=0;i<newLen;i++) out[i] = samples[Math.floor(i*ratio)] || 0;
  }
  // normalize message to -1..1
  let max = 0; for(let v of out) if(Math.abs(v)>max) max = Math.abs(v);
  if(max<1e-6) max = 1;
  for(let i=0;i<out.length;i++) out[i] /= max;
  rawMessage = out;
  // create an AudioBuffer for message preview
  messageBuffer = audioCtx.createBuffer(1, rawMessage.length, sr);
  messageBuffer.copyToChannel(rawMessage,0,0);
  drawWave(document.getElementById('msgCanvas'), rawMessage, Math.max(1, Math.floor(rawMessage.length/800)));
}

function generateAMandFM(){
  if(!rawMessage) { alert('Load or record an audio message first.'); return; }
  sr = parseInt(sampleRateEl.value) || 44100;
  const fc = parseFloat(carrierFreqEl.value) || 10000;
  const amIndex = parseFloat(amIndexEl.value) || 0.6;
  const fmDev = parseFloat(fmDevEl.value) || 3000;

  const N = rawMessage.length;
  // create output Float32Arrays
  const am = new Float32Array(N);
  const fm = new Float32Array(N);

  // generate carrier and modulated
  let phase = 0;
  const twoPI = 2*Math.PI;
  for(let i=0;i<N;i++){
    const t = i/sr;
    const msg = rawMessage[i]; // in -1..1
    // AM: (1 + m*msg) * sin(2πfc t)
    const carrier = Math.sin(twoPI*fc*t);
    am[i] = (1 + amIndex*msg) * carrier;
    // FM: integrate instantaneous frequency
    const instFreq = fc + fmDev * msg; // instantaneous frequency
    phase += twoPI * instFreq / sr;
    fm[i] = Math.sin(phase);
  }

  // normalize outputs to avoid clipping
  function normalize(arr){
    let m=0; for(let v of arr) if(Math.abs(v)>m) m=Math.abs(v);
    if(m<1e-6) return arr;
    const f = 0.95/m;
    for(let i=0;i<arr.length;i++) arr[i]*=f;
    return arr;
  }
  normalize(am); normalize(fm);

  // create AudioBuffers for playback
  amBuffer = audioCtx.createBuffer(1,N,sr);
  fmBuffer = audioCtx.createBuffer(1,N,sr);
  amBuffer.copyToChannel(am,0,0);
  fmBuffer.copyToChannel(fm,0,0);

  // draw carrier preview: short portion
  const carrierPreview = new Float32Array(800);
  for(let i=0;i<carrierPreview.length;i++) carrierPreview[i] = Math.sin(2*Math.PI*fc*(i/sr));
  drawWave(document.getElementById('carrierCanvas'), carrierPreview, 1);
  drawWave(document.getElementById('amCanvas'), am, Math.max(1, Math.floor(N/800)));
  drawWave(document.getElementById('fmCanvas'), fm, Math.max(1, Math.floor(N/800)));

  // prepare downloadable WAVs
  downloadAM.href = bufferToWavURL(amBuffer);
  downloadAM.download = 'am_modulated.wav';
  downloadFM.href = bufferToWavURL(fmBuffer);
  downloadFM.download = 'fm_modulated.wav';

  alert('AM and FM generated — you can preview and download.');
}

processBtn.addEventListener('click', generateAMandFM);

function playAudioBuffer(buf){
  if(!buf){ alert('No buffer ready.'); return; }
  const src = audioCtx.createBufferSource();
  src.buffer = buf;
  src.connect(audioCtx.destination);
  src.start();
}

playMsg.addEventListener('click', ()=>{
  if(!messageBuffer) { alert('No message loaded.'); return; }
  playAudioBuffer(messageBuffer);
});
playAM.addEventListener('click', ()=> playAudioBuffer(amBuffer));
playFM.addEventListener('click', ()=> playAudioBuffer(fmBuffer));

// utility to convert AudioBuffer -> WAV blob URL
function bufferToWavURL(audioBuffer){
  const numOfChan = audioBuffer.numberOfChannels;
  const length = audioBuffer.length * numOfChan * 2 + 44;
  const buffer = new ArrayBuffer(length);
  const view = new DataView(buffer);

  const writeString = function(view, offset, string){
    for (let i = 0; i < string.length; i++) view.setUint8(offset + i, string.charCodeAt(i));
  };

  let offset = 0;
  writeString(view, offset, 'RIFF'); offset += 4;
  view.setUint32(offset, 36 + audioBuffer.length * numOfChan * 2, true); offset += 4;
  writeString(view, offset, 'WAVE'); offset += 4;
  writeString(view, offset, 'fmt '); offset += 4;
  view.setUint32(offset, 16, true); offset += 4;
  view.setUint16(offset, 1, true); offset += 2;
  view.setUint16(offset, numOfChan, true); offset += 2;
  view.setUint32(offset, audioBuffer.sampleRate, true); offset += 4;
  view.setUint32(offset, audioBuffer.sampleRate * numOfChan * 2, true); offset += 4;
  view.setUint16(offset, numOfChan * 2, true); offset += 2;
  view.setUint16(offset, 16, true); offset += 2;
  writeString(view, offset, 'data'); offset += 4;
  view.setUint32(offset, audioBuffer.length * numOfChan * 2, true); offset += 4;

  // write interleaved data
  if(numOfChan === 1){
    const chan = audioBuffer.getChannelData(0);
    for(let i=0;i<chan.length;i++, offset+=2){
      const s = Math.max(-1, Math.min(1, chan[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
  } else {
    // interleave
    const ch0 = audioBuffer.getChannelData(0);
    const ch1 = audioBuffer.getChannelData(1);
    for(let i=0;i<ch0.length;i++){
      let s = Math.max(-1, Math.min(1, ch0[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true); offset+=2;
      s = Math.max(-1, Math.min(1, ch1[i]));
      view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true); offset+=2;
    }
  }

  const blob = new Blob([view], { type: 'audio/wav' });
  return URL.createObjectURL(blob);
}

// initially disable download links until generated
[downloadAM, downloadFM].forEach(a=>{ a.href='#'; a.onclick = (e)=>{ if(!amBuffer && !fmBuffer){ e.preventDefault(); alert('Generate first.'); } }; });

</script>
</body>
</html>
